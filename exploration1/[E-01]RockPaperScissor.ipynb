{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "palestinian-importance",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-pressing",
   "metadata": {},
   "source": [
    "**trainset : 양재캠퍼스의 데이터(주먹 : 1432, 가위 : 1427, 보 : 1427개) + 강남캠퍼스 데이터(주먹:203, 가위: 203, 보: 203)**\n",
    "\n",
    "\n",
    "**testset : 강남캠퍼스의 데이터(주먹 : 599, 가위: 599, 보: 599)**\n",
    "\n",
    "trainset과 testest은 다른사람의 데이터를 사용하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-carolina",
   "metadata": {},
   "source": [
    "### 1. 데이터 가져오기 및 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "editorial-automation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nasty-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rsp_dict = {'rock' : 0, 'scissor' : 0, 'paper' : 0} #train 데이터의 바위, 가위, 보 갯수를 세어주는 dictionary\n",
    "test_rsp_dict = {'rock' : 0, 'scissor' : 0, 'paper' : 0} #train 데이터의 바위, 가위, 보 갯수를 세어주는 dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "retired-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 데이터와 test데이터의 경로를 가진 리스트\n",
    "train_file_path = [\"/aiffel/aiffel/exploration/exploration1/rock\", \"/aiffel/aiffel/exploration/exploration1/scissor\", \"/aiffel/aiffel/exploration/exploration1/paper\"]\n",
    "test_file_path = [\"/aiffel/aiffel/exploration/exploration1/rocks_complete\", \"/aiffel/aiffel/exploration/exploration1/scissors_complete\", \"/aiffel/aiffel/exploration/exploration1/papers_complete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lightweight-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train_resize_images(img_path):\n",
    "    \n",
    "    images = glob.glob(img_path + \"/*.jpg\")\n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "    \n",
    "    if 'rock' in img_path.split('/'):\n",
    "        train_rsp_dict['rock'] = len(images)\n",
    "    elif 'scissor' in img_path.split('/'):\n",
    "        train_rsp_dict['scissor'] = len(images)\n",
    "    else:\n",
    "        train_rsp_dict['paper'] = len(images)\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "    \n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "actual-details",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1641  images to be resized.\n",
      "1641  images resized.\n",
      "1636  images to be resized.\n",
      "1636  images resized.\n",
      "1636  images to be resized.\n",
      "1636  images resized.\n"
     ]
    }
   ],
   "source": [
    "for f in train_file_path:\n",
    "    train_resize_images(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "integral-sperm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rock': 1641, 'scissor': 1636, 'paper': 1636}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rsp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electric-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resize_images(img_path):\n",
    "    \n",
    "    images = glob.glob(img_path + \"/*.jpg\")\n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "    \n",
    "    #주먹 가위 보가 각각 몇개씩 들어있는지 파악하도록 딕셔너리에 저장\n",
    "    if 'rocks_complete' in img_path.split('/'):\n",
    "        test_rsp_dict['rock'] = len(images)\n",
    "    elif 'scissors_complete' in img_path.split('/'):\n",
    "        test_rsp_dict['scissor'] = len(images)\n",
    "    else:\n",
    "        test_rsp_dict['paper'] = len(images)\n",
    "    \n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "    \n",
    "    target_size = (28, 28)\n",
    "    for img in images:\n",
    "        old_img = Image.open(img)\n",
    "        new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "selected-audience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599  images to be resized.\n",
      "599  images resized.\n",
      "599  images to be resized.\n",
      "599  images resized.\n",
      "599  images to be resized.\n",
      "599  images resized.\n"
     ]
    }
   ],
   "source": [
    "for f in test_file_path:\n",
    "    test_resize_images(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-facing",
   "metadata": {},
   "source": [
    "### 2. 이미지를 train 과 test 행렬에 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ideal-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 4913 입니다.\n",
      "x_train shape: (4913, 28, 28, 3)\n",
      "y_train shape: (4913,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_dir_path = \"/aiffel/aiffel/exploration/exploration1/\"\n",
    "number_of_train_data = train_rsp_dict['rock'] + train_rsp_dict['scissor'] + train_rsp_dict['paper']\n",
    "\n",
    "\n",
    "def load_train_data(img_path, number_of_train_data):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #train, test 각각의  이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    train_imgs = np.zeros(number_of_train_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_train_data,img_size,img_size,color)\n",
    "    train_labels = np.zeros(number_of_train_data, dtype=np.int32)\n",
    "    \n",
    "    train_idx = 0\n",
    "\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        train_imgs[train_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        train_labels[train_idx]=0   # 가위 : 0\n",
    "        train_idx = train_idx+1\n",
    "\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        train_imgs[train_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        train_labels[train_idx]=1   # 바위 : 1\n",
    "        train_idx = train_idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        train_imgs[train_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        train_labels[train_idx]=2   # 보 : 2\n",
    "        train_idx = train_idx+1\n",
    "     \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", number_of_train_data,\"입니다.\")\n",
    "    return train_imgs, train_labels\n",
    "\n",
    "x_train, y_train = load_train_data(image_dir_path, number_of_train_data)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "billion-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 1797 입니다.\n",
      "x_test shape: (1797, 28, 28, 3)\n",
      "y_test shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_dir_path = \"/aiffel/aiffel/exploration/exploration1/\"\n",
    "number_of_test_data = test_rsp_dict['rock'] + test_rsp_dict['scissor'] + test_rsp_dict['paper']\n",
    "\n",
    "def test_load_data(img_path, number_of_test_data):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #train, test 각각의  이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    test_imgs = np.zeros(number_of_test_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_test_data,img_size,img_size,color)\n",
    "    test_labels = np.zeros(number_of_test_data,dtype=np.int32)\n",
    "\n",
    "    test_idx = 0\n",
    "\n",
    "    for file in glob.iglob(img_path+'/scissors_complete/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)      \n",
    "        test_imgs[test_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        test_labels[test_idx]=0    #   가위 : 0\n",
    "        test_idx = test_idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rocks_complete/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        test_imgs[test_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        test_labels[test_idx]= 1  # 바위 : 1\n",
    "        test_idx = test_idx+1\n",
    "    \n",
    "    for file in glob.iglob(img_path+'/papers_complete/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        test_imgs[test_idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        test_labels[test_idx]=2   # 보 : 2\n",
    "        test_idx = test_idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\", number_of_test_data,\"입니다.\")\n",
    "    return test_imgs, test_labels\n",
    "\n",
    "x_test, y_test = test_load_data(image_dir_path, number_of_test_data)\n",
    "\n",
    "# 입력은 0~1 사이의 값으로 정규화\n",
    "x_test_norm = x_test/255.0\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-northwest",
   "metadata": {},
   "source": [
    "### 3. 모델 생성 및 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "final-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "timely-assist",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 93,635\n",
      "Trainable params: 93,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.1100 - accuracy: 0.3355\n",
      "Epoch 2/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 1.0727 - accuracy: 0.4076\n",
      "Epoch 3/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.9626 - accuracy: 0.5173\n",
      "Epoch 4/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.8342 - accuracy: 0.6076\n",
      "Epoch 5/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.7015 - accuracy: 0.6897\n",
      "Epoch 6/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6121 - accuracy: 0.7368\n",
      "Epoch 7/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5488 - accuracy: 0.7663\n",
      "Epoch 8/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4975 - accuracy: 0.8037\n",
      "Epoch 9/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4523 - accuracy: 0.8108\n",
      "Epoch 10/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4300 - accuracy: 0.8295\n",
      "Epoch 11/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3989 - accuracy: 0.8447\n",
      "Epoch 12/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3865 - accuracy: 0.8555\n",
      "Epoch 13/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3383 - accuracy: 0.8679\n",
      "Epoch 14/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3509 - accuracy: 0.8710\n",
      "Epoch 15/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2810 - accuracy: 0.8868\n",
      "Epoch 16/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2904 - accuracy: 0.8931\n",
      "Epoch 17/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2795 - accuracy: 0.8922\n",
      "Epoch 18/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2787 - accuracy: 0.8985\n",
      "Epoch 19/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2493 - accuracy: 0.9048\n",
      "Epoch 20/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2172 - accuracy: 0.9172\n",
      "Epoch 21/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2228 - accuracy: 0.9168\n",
      "Epoch 22/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9209\n",
      "Epoch 23/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2115 - accuracy: 0.9280\n",
      "Epoch 24/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9251\n",
      "Epoch 25/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2030 - accuracy: 0.9260\n",
      "Epoch 26/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1941 - accuracy: 0.9309\n",
      "Epoch 27/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9209\n",
      "Epoch 28/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1574 - accuracy: 0.9413\n",
      "Epoch 29/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9337\n",
      "Epoch 30/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.9414\n",
      "Epoch 31/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1586 - accuracy: 0.9430\n",
      "Epoch 32/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1642 - accuracy: 0.9372\n",
      "Epoch 33/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.9388\n",
      "Epoch 34/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1495 - accuracy: 0.9456\n",
      "Epoch 35/35\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9467\n",
      "57/57 - 0s - loss: 2.2739 - accuracy: 0.7045\n",
      "test_loss: 2.273876905441284 \n",
      "test_accuracy: 0.7045075297355652\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=128\n",
    "#n_dense_1= 32\n",
    "#n_dense_2 = 128\n",
    "n_train_epoch=35\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu',input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Dropout(rate = 0.5)) #Dropout을 통한 정규화\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Dropout(rate = 0.5)) #Dropout을 통한 정규화\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "#model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "#model.add(keras.layers.Flatten())\n",
    "#model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.GlobalAveragePooling2D()) #Maxpooling 대신 GAP를 FC Layer를 사용했을 때보다 사용하여 파라미터도 줄인다.\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy', #label이 정수값이므로 loss로 sparse_categorical_crossentropy 사용\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-light",
   "metadata": {},
   "source": [
    "### GAP(Global Average Pooling)의 이점\n",
    "\n",
    "\n",
    "\n",
    "- FC(Fully Connected)를 사용할 때 위치정보를 잃게 되는데 GAP는 공간정보를 반영하기 때문에 공간적 해석용이\n",
    "- 파라미터 수를 줄여줄 수 있어 과적합을 피할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-moderator",
   "metadata": {},
   "source": [
    "### 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-tonight",
   "metadata": {},
   "source": [
    "처음에는 코랩을 통해서 실습을 진행했는데 colab 서버에 따라 resize할때 굉장히 시간이 낭비되었었다.\n",
    "<br>\n",
    "그래서 다시 아이펠 주피터 클라우드환경에서 데이터 업로드 및 알집 풀기를 다시했어야 했는데 아지트에 선웅님과 형준님께서 올려주신 글덕분에 빠르게 해결할 수 있었다. \n",
    "<br>\n",
    "또한, 데이터도 병휘님께서 양재분들의 데이터를 수집해주셔서 보다 좋은 환경에서 실험을 해볼 수 있었다.\n",
    "<br>\n",
    "감사합니다 ㅠㅠ\n",
    "<br>\n",
    "첫 실험은 컨볼루션을 2개로 하고, FC로 연결한 구조로부터 시작하여 epoch, filter수, Dense수등의 파라미터를 조절하며 실행을 진행했었다. 이는 train set이 빠르게 accuracy가 증가하였으나 실험을 할때마다 도출된 test accuarcy의 편차가 너무 컸다. 이는 train_set에 대해 과적합이 되고 있는 것을 보여준 것으로 생각된다. \n",
    "<br>\n",
    "그 다음은 컨볼루션을 3개로 하면서 Dropout을 컨볼루션 다음마다 도입하고, FC다음에도 도입해보았다. 0.5이상은 나온것같은데 0.6을 보기에는 힘들었다.\n",
    "<br>\n",
    "데이터에 비하여 파라미터 수도 굉장히 많았기 때문에 파라미터를 줄이면서 보다 robust한 모델을 만들려면 어떻게 해야될지 찾아보다가 GAP개념을 발견하였다. FC대신에 GAP를 이용하는 경우에 대한 내용을 살펴보며 도입을 해보았는데 도입 이후부터는 0.6이상의 값들이 잘 나오고 있는 것을 확인할 수 있었다.\n",
    "<br>\n",
    "내 생각에는 conv의 filter 수가 커지면 커질수록 parameter수가 늘어나는데 마지막에 GAP가 파라미터 수를 줄여주는 효과 및 공간정보를 함축적으로 요약하며, FC를 연결하여 파라미터수를 늘릴 필요가 없기 때문에 도움이 된것으로 생각된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
